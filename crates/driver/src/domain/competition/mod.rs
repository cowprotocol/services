use {
    self::solution::settlement,
    super::{
        Mempools,
        mempools::DelegatedSubmission,
        time::{self, Remaining},
    },
    crate::{
        domain::{
            competition::{solution::Settlement, sorting::SortingStrategy},
            eth,
            time::DeadlineExceeded,
        },
        infra::{
            self,
            Simulator,
            blockchain::Ethereum,
            notify,
            observe::{self, metrics},
            simulator::{RevertError, SimulatorError},
            solver::{self, Account, SolutionMerging, Solver},
        },
        util::math,
    },
    alloy::{network::TxSigner as _, primitives::Bytes},
    axum::{body::Body, http::Request},
    futures::{StreamExt, future::Either, stream::FuturesUnordered},
    itertools::Itertools,
    std::{
        cmp::Reverse,
        collections::{HashMap, HashSet, VecDeque},
        sync::{Arc, Mutex},
        time::{Duration, Instant},
    },
    tokio::{
        sync::{mpsc, oneshot},
        task,
    },
    tracing::{Instrument, instrument},
};

pub mod auction;
pub mod order;
mod pre_processing;
pub mod risk_detector;
pub mod solution;
pub mod sorting;

pub use {auction::Auction, order::Order, pre_processing::DataAggregator, solution::Solution};

use crate::{domain::BlockNo, infra::notify::liquidity_sources::LiquiditySourceNotifying};

type BalanceGroup = (order::Trader, eth::TokenAddress, order::SellTokenBalance);
type Balances = HashMap<BalanceGroup, order::SellAmount>;

/// An ongoing competition. There is one competition going on per solver at any
/// time. The competition stores settlements to solutions generated by the
/// driver, and allows them to be executed onchain when requested later. The
/// solutions expire after a certain amount of time, at which point trying to
/// use them will return an `[Error::InvalidSolutionId]`.
/// Pool of submission accounts for EIP-7702 parallel settlement. Accounts
/// are borrowed for the duration of a settlement and returned afterward.
#[derive(Debug)]
struct SubmissionAccountPool {
    /// Sender to return accounts after use.
    release: mpsc::Sender<Account>,
    /// Receiver to acquire an idle account.
    acquire: tokio::sync::Mutex<mpsc::Receiver<Account>>,
}

impl SubmissionAccountPool {
    fn new(accounts: Vec<Account>) -> Self {
        let (tx, rx) = mpsc::channel(accounts.len());
        for account in accounts {
            tx.try_send(account)
                .expect("channel has sufficient capacity");
        }
        Self {
            release: tx,
            acquire: tokio::sync::Mutex::new(rx),
        }
    }

    /// Acquire a submission account from the pool, returning an RAII guard
    /// that returns the account on drop. Returns `None` if the pool is
    /// closed.
    async fn acquire(&self) -> Option<AccountGuard> {
        let account = self.acquire.lock().await.recv().await?;
        Some(AccountGuard {
            account,
            release_sender: self.release.clone(),
        })
    }
}

/// RAII guard that returns the submission account to the pool on drop,
/// ensuring the account is not leaked even if the future is cancelled.
struct AccountGuard {
    account: Account,
    release_sender: mpsc::Sender<Account>,
}

impl std::ops::Deref for AccountGuard {
    type Target = Account;

    fn deref(&self) -> &Account {
        &self.account
    }
}

impl Drop for AccountGuard {
    fn drop(&mut self) {
        let account = std::mem::replace(&mut self.account, Account::Address(Default::default()));
        let sender = self.release_sender.clone();
        tokio::spawn(async move {
            if sender.send(account).await.is_err() {
                tracing::error!("failed to return submission account to pool: channel closed");
            }
        });
    }
}

#[derive(Debug)]
pub struct Competition {
    pub solver: Solver,
    pub eth: Ethereum,
    pub liquidity: infra::liquidity::Fetcher,
    pub liquidity_sources_notifier: infra::notify::liquidity_sources::Notifier,
    pub simulator: Simulator,
    pub mempools: Mempools,
    /// Cached solutions with the most recent solutions at the front.
    pub settlements: Mutex<VecDeque<Settlement>>,
    /// bad token and orders detector
    pub risk_detector: Arc<risk_detector::Detector>,
    fetcher: Arc<pre_processing::DataAggregator>,
    settle_queue: mpsc::Sender<SettleRequest>,
    order_sorting_strategies: Vec<Arc<dyn sorting::SortingStrategy>>,
    /// When configured, enables concurrent settlement submission via EIP-7702.
    submission_account_pool: Option<SubmissionAccountPool>,
    /// 1-permit semaphore: when acquired, the solver EOA submits directly
    /// (no 7702 forwarding overhead). Only present when
    /// `submission_account_pool` is configured.
    settlement_in_flight: Option<tokio::sync::Semaphore>,
}

impl Competition {
    #[expect(clippy::too_many_arguments)]
    pub fn new(
        solver: Solver,
        eth: Ethereum,
        liquidity: infra::liquidity::Fetcher,
        liquidity_sources_notifier: infra::notify::liquidity_sources::Notifier,
        simulator: Simulator,
        mempools: Mempools,
        risk_detector: Arc<risk_detector::Detector>,
        fetcher: Arc<DataAggregator>,
        order_sorting_strategies: Vec<Arc<dyn sorting::SortingStrategy>>,
    ) -> Arc<Self> {
        let submission_accounts = solver.submission_accounts().to_vec();
        let submission_account_pool = if submission_accounts.is_empty() {
            None
        } else {
            tracing::info!(
                count = submission_accounts.len(),
                "EIP-7702 parallel submission enabled"
            );
            Some(SubmissionAccountPool::new(submission_accounts))
        };

        let direct_submission_slot = submission_account_pool
            .as_ref()
            .map(|_| tokio::sync::Semaphore::new(1));

        // When using parallel submission, the queue size should accommodate all
        // submission accounts plus the direct solver slot.
        let queue_size = match &submission_account_pool {
            Some(pool) => pool.release.max_capacity() + 1,
            None => solver.settle_queue_size(),
        };
        let (settle_sender, settle_receiver) = mpsc::channel(queue_size);

        let competition = Arc::new(Self {
            solver,
            eth,
            liquidity,
            liquidity_sources_notifier,
            simulator,
            mempools,
            settlements: Default::default(),
            settle_queue: settle_sender,
            risk_detector,
            fetcher,
            order_sorting_strategies,
            submission_account_pool,
            settlement_in_flight: direct_submission_slot,
        });

        let competition_clone = Arc::clone(&competition);
        tokio::spawn(async move {
            competition_clone
                .process_settle_requests(settle_receiver)
                .await;
        });

        competition
    }

    /// Solve an auction as part of this competition.
    pub async fn solve(&self, request: Request<Body>) -> Result<Option<Solved>, Error> {
        let start = Instant::now();
        let timer = ::observe::metrics::metrics()
            .on_auction_overhead_start("driver", "pre_processing_total");

        let tasks = self
            .fetcher
            .start_or_get_tasks_for_auction(request)
            .await
            .map_err(|err| {
                tracing::error!(?err, "pre-processing auction failed");
                Error::MalformedRequest
            })?;
        let mut auction = Arc::unwrap_or_clone(tasks.auction.await);

        let settlement_contract = *self.eth.contracts().settlement().address();
        let solver_address = self.solver.address();
        let order_sorting_strategies = self.order_sorting_strategies.clone();

        // Add the CoW AMM orders to the auction
        let cow_amm_orders = tasks.cow_amm_orders.await;
        auction.orders.extend(cow_amm_orders.iter().cloned());

        let settlement = settlement_contract;
        let sort_orders_future = Self::run_blocking_with_timer("sort_orders", move || {
            // Use spawn_blocking() because a lot of CPU bound computations are happening
            // and we don't want to block the runtime for too long.
            Self::sort_orders(
                auction,
                solver_address,
                order_sorting_strategies,
                settlement,
            )
        });

        // We can sort the orders and fetch auction data in parallel
        let (auction, balances, app_data) =
            tokio::join!(sort_orders_future, tasks.balances, tasks.app_data);

        let auction = Self::run_blocking_with_timer("update_orders", move || {
            // Same as before with sort_orders, we use spawn_blocking() because a lot of CPU
            // bound computations are happening and we want to avoid blocking
            // the runtime.
            Self::update_orders(auction, balances, app_data, cow_amm_orders, &settlement)
        })
        .await;

        // We can run bad token filtering and liquidity fetching in parallel
        let (liquidity, auction) = tokio::join!(
            async {
                match self.solver.liquidity() {
                    solver::Liquidity::Fetch => tasks.liquidity.await,
                    solver::Liquidity::Skip => Arc::new(Vec::new()),
                }
            },
            self.without_unsupported_orders(auction)
        );

        let elapsed = start.elapsed();
        metrics::get()
            .auction_preprocessing
            .with_label_values(&["total"])
            .observe(elapsed.as_secs_f64());
        drop(timer);
        tracing::debug!(?elapsed, "auction task execution time");

        if auction.orders.is_empty() {
            tracing::info!("no orders left after pre-processing; skipping solving");
            return Ok(None);
        }

        let auction = &auction;

        // Fetch the solutions from the solver.
        let solutions = self
            .solver
            .solve(auction, &liquidity)
            .await
            .inspect_err(|err| {
                if err.is_timeout() {
                    notify::solver_timeout(&self.solver, auction.id());
                }
            })?;

        let deadline = auction.deadline(self.solver.timeouts()).driver();
        observe::postprocessing(&solutions, deadline);

        // Discard solutions that don't have unique ID.
        let mut ids = HashSet::new();
        let solutions = solutions.into_iter().filter(|solution| {
            if !ids.insert(solution.id().clone()) {
                observe::duplicated_solution_id(self.solver.name(), solution.id());
                notify::duplicated_solution_id(&self.solver, auction.id(), solution.id());
                false
            } else {
                true
            }
        });

        // Discard empty solutions.
        let solutions = solutions.filter(|solution| {
            if solution.is_empty(auction.surplus_capturing_jit_order_owners()) {
                observe::empty_solution(self.solver.name(), solution.id());
                notify::empty_solution(&self.solver, auction.id(), solution.id().clone());
                false
            } else {
                true
            }
        });

        let all_solutions = match self.solver.solution_merging() {
            SolutionMerging::Allowed {
                max_orders_per_merged_solution,
            } => merge(solutions, auction, max_orders_per_merged_solution),
            SolutionMerging::Forbidden => solutions.collect(),
        };

        // Encode solutions into settlements (streamed).
        let encoded = all_solutions
            .into_iter()
            .map(|solution| async move {
                let id = solution.id().clone();
                let orders: Vec<_> = solution
                    .user_trades()
                    .map(|trade| trade.order().uid)
                    .collect();
                let has_haircut = solution.has_haircut();
                observe::encoding(&id);
                let settlement = solution
                    .encode(
                        auction,
                        &self.eth,
                        &self.simulator,
                        self.solver.solver_native_token(),
                    )
                    .await;
                (id, orders, has_haircut, settlement)
            })
            .collect::<FuturesUnordered<_>>()
            .filter_map(|(id, orders, has_haircut, result)| async move {
                match result {
                    Ok(solution) => {
                        self.risk_detector.encoding_succeeded(&orders);
                        Some(solution)
                    }
                    // don't report on errors coming from solution merging
                    Err(_err) if id.solutions().len() > 1 => None,
                    Err(err) => {
                        self.risk_detector.encoding_failed(&orders);
                        observe::encoding_failed(self.solver.name(), &id, &err, has_haircut);
                        // don't notify on errors for solutions with haircut
                        if !has_haircut {
                            notify::encoding_failed(&self.solver, auction.id(), &id, &err);
                        }
                        None
                    }
                }
            });

        // Encode settlements as they arrive until there are no more new settlements or
        // timeout is reached.
        let mut settlements = Vec::new();
        let future = async {
            let mut encoded = std::pin::pin!(encoded);
            while let Some(settlement) = encoded.next().await {
                settlements.push(settlement);
            }
        };
        if tokio::time::timeout(deadline.remaining().unwrap_or_default(), future)
            .await
            .is_err()
        {
            observe::postprocessing_timed_out(&settlements);
            notify::postprocessing_timed_out(&self.solver, auction.id())
        }

        // Score the settlements.
        let scores = settlements
            .into_iter()
            .map(|settlement| {
                observe::scoring(&settlement);
                (
                    settlement.score(
                        &auction.native_prices(),
                        auction.surplus_capturing_jit_order_owners(),
                    ),
                    settlement,
                )
            })
            .collect_vec();

        // Filter out settlements which failed scoring.
        let scores = scores
            .into_iter()
            .filter_map(|(result, settlement)| {
                result
                    .inspect_err(|err| {
                        observe::scoring_failed(self.solver.name(), err);
                        notify::scoring_failed(
                            &self.solver,
                            auction.id(),
                            settlement.solution(),
                            err,
                        );
                    })
                    .ok()
                    .map(|score| (score, settlement))
            })
            .collect_vec();

        // Observe the scores.
        for (score, settlement) in scores.iter() {
            observe::score(settlement, score);
        }

        // Pick the best-scoring settlement.
        let (mut score, settlement) = scores
            .into_iter()
            .max_by_key(|(score, _)| score.to_owned())
            .map(|(score, settlement)| {
                (
                    Solved {
                        id: settlement.solution().clone(),
                        score,
                        trades: settlement.orders(),
                        prices: settlement.prices(),
                        gas: Some(settlement.gas.estimate),
                    },
                    settlement,
                )
            })
            .unzip();

        let Some(settlement) = settlement else {
            // Don't wait for the deadline because we can't produce a solution anyway.
            return Ok(score);
        };
        let solution_id = settlement.solution().get();

        {
            let mut lock = self.settlements.lock().unwrap();
            lock.push_front(settlement.clone());

            /// Number of solutions that may be cached at most.
            const MAX_SOLUTION_STORAGE: usize = 5;
            lock.truncate(MAX_SOLUTION_STORAGE);
        }

        // Re-simulate the solution on every new block until the deadline ends to make
        // sure we actually submit a working solution close to when the winner
        // gets picked by the procotol.
        if let Ok(remaining) = deadline.remaining() {
            let score_ref = &mut score;
            let has_haircut = settlement.has_haircut();
            let simulate_on_new_blocks = async move {
                let mut stream =
                    ethrpc::block_stream::into_stream(self.eth.current_block().clone());
                while let Some(block) = stream.next().await {
                    if let Err(infra::simulator::Error::Revert(err)) =
                        self.simulate_settlement(&settlement).await
                    {
                        observe::winner_voided(self.solver.name(), block, &err, has_haircut);
                        *score_ref = None;
                        self.settlements
                            .lock()
                            .unwrap()
                            .retain(|s| s.solution().get() != solution_id);
                        // Only notify solver if solution doesn't have haircut
                        if !has_haircut {
                            notify::simulation_failed(
                                &self.solver,
                                auction.id(),
                                settlement.solution(),
                                &infra::simulator::Error::Revert(err),
                                true,
                            );
                        }
                        return;
                    }
                }
            };
            let _ = tokio::time::timeout(remaining, simulate_on_new_blocks).await;
        }

        Ok(score)
    }

    // Oders already need to be sorted from most relevant to least relevant so that
    // we allocate balances for the most relevants first.
    fn sort_orders(
        mut auction: Auction,
        solver: eth::Address,
        order_sorting_strategies: Vec<Arc<dyn SortingStrategy>>,
        _settlement_contract: eth::Address,
    ) -> Auction {
        sorting::sort_orders(
            &mut auction.orders,
            &auction.tokens,
            &solver,
            &order_sorting_strategies,
        );
        auction
    }

    /// Removes orders that cannot be filled due to missing funds of the owner
    /// and updates the fetched app data.
    /// It allocates available funds from left to right so the orders should
    /// already be sorted by priority going in.
    fn update_orders(
        mut auction: Auction,
        balances: Arc<Balances>,
        app_data: Arc<HashMap<order::app_data::AppDataHash, Arc<app_data::ValidatedAppData>>>,
        cow_amm_orders: Arc<Vec<Order>>,
        settlement_contract: &eth::Address,
    ) -> Auction {
        // Clone balances since we only aggregate data once but each solver needs
        // to use and modify the data individually.
        let mut balances = balances.as_ref().clone();
        let cow_amms: HashSet<_> = cow_amm_orders.iter().map(|o| o.uid).collect();

        // The auction that we receive from the `autopilot` assumes that there
        // is sufficient balance to completely cover all the orders. **This is
        // not the case** (as the protocol should not chose which limit orders
        // get filled for some given sell token balance). This loop goes through
        // the priority sorted orders and allocates the available user balance
        // to each order, and potentially scaling the order's `available` amount
        // down in case the available user balance is only enough to partially
        // cover the rest of the order.
        auction.orders.retain_mut(|order| {
            if cow_amms.contains(&order.uid) {
                // cow amm orders already get constructed fully initialized
                // so we don't have to handle them here anymore.
                // Without this short circuiting logic they would get filtered
                // out later because we don't bother fetching their balances
                // for performance reasons.
                return true;
            }

            // Update order app data if it was fetched.
            if let Some(fetched_app_data) = app_data.get(&order.app_data.hash()) {
                order.app_data = fetched_app_data.clone().into();
                if order.app_data.flashloan().is_some() {
                    // If an order requires a flashloan we assume all the necessary
                    // sell tokens will come from there. But the receiver must be the
                    // settlement contract because that is how the driver expects
                    // the flashloan to be repaid for now.
                    return order.receiver.as_ref() == Some(settlement_contract);
                }
            }

            // wrappers can produce the required funds at settlement time
            if !order.app_data.wrappers().is_empty() {
                return true;
            }

            let remaining_balance = match balances.get_mut(&(
                order.trader(),
                order.sell.token,
                order.sell_token_balance,
            )) {
                Some(balance) => balance,
                None => {
                    let reason = observe::OrderExcludedFromAuctionReason::CouldNotFetchBalance;
                    observe::order_excluded_from_auction(order, reason);
                    return false;
                }
            };

            let max_sell = order::SellAmount(order.available().sell.amount.0);

            let allocated_balance = match order.partial {
                order::Partial::Yes { .. } => max_sell.min(*remaining_balance),
                order::Partial::No if max_sell <= *remaining_balance => max_sell,
                _ => order::SellAmount::default(),
            };
            if allocated_balance.0.is_zero() {
                observe::order_excluded_from_auction(
                    order,
                    observe::OrderExcludedFromAuctionReason::InsufficientBalance,
                );
                return false;
            }

            // We need to scale the available amount in the order based on
            // allocated balance. We cannot naively just set the `available`
            // amount to equal the `allocated_balance` because of two reasons:
            // 1. They are in different units. `available` is a `TargetAmount` which means
            //    it would be in buy token for buy orders and not in sell token like the
            //    `allocated_balance`
            // 2. Account for fees. Even in the case of sell orders, `available` is
            //    potentially different to `allocated_balance` because of fee scaling. For
            //    example, imagine a partially fillable order selling 100 tokens with a fee
            //    of 10 for a user with a balance of 50. The `allocated_balance` would be 50
            //    tokens, but the `available` amount needs to be less! We want the
            //    following: `available + (fee * available / sell) <= allocated_balance`
            if let order::Partial::Yes { available } = &mut order.partial {
                *available = order::TargetAmount(
                    math::mul_ratio(available.0, allocated_balance.0, max_sell.0)
                        .unwrap_or_default(),
                );
            }
            if order.available().is_zero() {
                observe::order_excluded_from_auction(
                    order,
                    observe::OrderExcludedFromAuctionReason::OrderWithZeroAmountRemaining,
                );
                return false;
            }

            remaining_balance.0 -= allocated_balance.0;

            true
        });

        auction
    }

    /// Runs a blocking function on a background thread, timing it using the
    /// given stage name.
    pub async fn run_blocking_with_timer<T, F>(stage: &'static str, f: F) -> T
    where
        F: FnOnce() -> T + Send + 'static,
        T: Send + 'static,
    {
        task::spawn_blocking(move || {
            let _timer = metrics::get().processing_stage_timer(stage);
            let _timer2 = ::observe::metrics::metrics().on_auction_overhead_start("driver", stage);
            f()
        })
        .await
        .expect(
            "Either runtime was shut down before spawning the task or no OS threads are \
             available; no sense in handling those errors",
        )
    }

    pub async fn reveal(
        &self,
        solution_id: u64,
        auction_id: auction::Id,
    ) -> Result<Revealed, Error> {
        let settlement = self
            .settlements
            .lock()
            .unwrap()
            .iter()
            .find(|s| s.solution().get() == solution_id && s.auction_id == auction_id)
            .cloned()
            .ok_or(Error::SolutionNotAvailable)?;
        Ok(Revealed {
            internalized_calldata: settlement
                .transaction(settlement::Internalization::Enable)
                .input
                .clone(),
            uninternalized_calldata: settlement
                .transaction(settlement::Internalization::Disable)
                .input
                .clone(),
        })
    }

    /// Execute the solution generated as part of this competition. Use
    /// [`Competition::solve`] to generate the solution.
    pub async fn settle(
        &self,
        auction_id: auction::Id,
        solution_id: u64,
        submission_deadline: BlockNo,
    ) -> Result<Settled, Error> {
        let (response_sender, response_receiver) = oneshot::channel();

        let request = SettleRequest {
            auction_id,
            solution_id,
            submission_deadline,
            response_sender,
            tracing_span: tracing::Span::current(),
        };

        self.settle_queue.try_send(request).map_err(|err| {
            tracing::warn!(?err, "Failed to enqueue /settle request");
            Error::TooManyPendingSettlements
        })?;

        response_receiver.await.map_err(|err| {
            tracing::error!(?err, "Failed to dequeue /settle response");
            Error::SubmissionError
        })?
    }

    pub fn ensure_settle_queue_capacity(&self) -> Result<(), Error> {
        if self.settle_queue.capacity() == 0 {
            tracing::warn!("settlement queue is full; auction is rejected");
            Err(Error::TooManyPendingSettlements)
        } else {
            Ok(())
        }
    }

    async fn process_settle_requests(
        self: Arc<Self>,
        mut settle_receiver: mpsc::Receiver<SettleRequest>,
    ) {
        while let Some(request) = settle_receiver.recv().await {
            if self.submission_account_pool.is_some() {
                // EIP-7702 mode: spawn each settlement as a concurrent task.
                let this = Arc::clone(&self);
                tokio::spawn(async move {
                    this.handle_settle_request(request).await;
                });
            } else {
                // Legacy mode: process settlements sequentially.
                self.handle_settle_request(request).await;
            }
        }
    }

    async fn handle_settle_request(self: &Arc<Self>, request: SettleRequest) {
        let SettleRequest {
            auction_id,
            solution_id,
            submission_deadline,
            mut response_sender,
            tracing_span,
        } = request;
        async {
            if self.eth.current_block().borrow().number >= submission_deadline {
                if let Err(err) = response_sender.send(Err(DeadlineExceeded.into())) {
                    tracing::error!(
                        ?err,
                        "settle deadline exceeded. unable to return a response"
                    );
                }
                return;
            }

            observe::settling();
            let settle_fut =
                Box::pin(self.process_settle_request(auction_id, solution_id, submission_deadline));
            let closed_fut = Box::pin(response_sender.closed());
            let result = match futures::future::select(closed_fut, settle_fut).await {
                // Cancel the settlement task if the sender is closed (client likely
                // disconnected). This is a fallback to recover from issues
                // like a stuck driver (e.g., stalled block stream).
                Either::Left((_closed, settle_fut)) => {
                    tracing::debug!("autopilot terminated settle call");
                    // Add a grace period to give driver the last chance to cancel the
                    // tx if needed.
                    tokio::time::timeout(Duration::from_secs(1), settle_fut)
                        .await
                        .unwrap_or_else(|_| {
                            tracing::error!("didn't finish tx submission within grace period");
                            Err(DeadlineExceeded.into())
                        })
                }
                Either::Right((res, _)) => res,
            };
            observe::settled(self.solver.name(), &result);
            let _ = response_sender.send(result);
        }
        .instrument(tracing_span)
        .await
    }

    async fn process_settle_request(
        &self,
        auction_id: auction::Id,
        solution_id: u64,
        submission_deadline: BlockNo,
    ) -> Result<Settled, Error> {
        let settlement = {
            let mut lock = self.settlements.lock().unwrap();
            let index = lock
                .iter()
                .position(|s| s.solution().get() == solution_id && s.auction_id == auction_id)
                .ok_or(Error::SolutionNotAvailable)?;
            // remove settlement to ensure we can't settle it twice by accident
            lock.swap_remove_front(index)
                .ok_or(Error::SolutionNotAvailable)?
        };

        // Asynchronously notify liquidity sources to not block settlement execution.
        {
            let liquidity_sources_notifier_clone = self.liquidity_sources_notifier.clone();
            let settlement_clone = settlement.clone();
            tokio::spawn(async move {
                match liquidity_sources_notifier_clone
                    .settlement(&settlement_clone)
                    .await
                {
                    Ok(_) => {}
                    Err(err) => {
                        tracing::error!(?err, "Failed to notify liquidity sources on settlement");
                    }
                }
            });
        }

        // When EIP-7702 submission accounts are configured, decide whether to
        // submit directly from the solver EOA (cheaper, no forwarding) or via a
        // delegated submission account.
        //
        // The direct slot is a 1-permit semaphore: if no settlement is
        // in-flight the solver EOA submits directly; otherwise we fall back to
        // an EIP-7702 submission account. Semaphore is freed on drop.
        let (guard, _direct_permit) = if let Some(pool) = &self.submission_account_pool {
            let direct_slot = self
                .settlement_in_flight
                .as_ref()
                .expect("always set with pool");
            if let Ok(permit) = direct_slot.try_acquire() {
                tracing::debug!("no settlement in flight, submitting directly from solver EOA");
                (None, Some(permit))
            } else {
                tracing::debug!("settlement in flight, using EIP-7702 submission account");
                let account = pool.acquire().await.ok_or(Error::SubmissionError)?;
                (Some(account), None)
            }
        } else {
            (None, None)
        };

        let delegated_ctx = guard.as_ref().map(|g| DelegatedSubmission {
            submitter_eoa: g.address(),
            solver_eoa: self.solver.address(),
        });

        let executed = self
            .mempools
            .execute(&settlement, submission_deadline, delegated_ctx.as_ref())
            .await;

        notify::executed(
            &self.solver,
            settlement.auction_id,
            settlement.solution(),
            &executed,
        );

        match executed {
            Err(_) => Err(Error::SubmissionError),
            Ok(tx_hash) => Ok(Settled {
                internalized_calldata: settlement
                    .transaction(settlement::Internalization::Enable)
                    .input
                    .clone(),
                uninternalized_calldata: settlement
                    .transaction(settlement::Internalization::Disable)
                    .input
                    .clone(),
                tx_hash,
            }),
        }
    }

    /// The ID of the auction being competed on.
    pub fn auction_id(&self, solution_id: u64) -> Option<auction::Id> {
        self.settlements
            .lock()
            .unwrap()
            .iter()
            .find(|s| s.solution().get() == solution_id)
            .map(|s| s.auction_id)
    }

    /// Returns whether the settlement can be executed or would revert.
    async fn simulate_settlement(
        &self,
        settlement: &Settlement,
    ) -> Result<(), infra::simulator::Error> {
        let tx = settlement.transaction(settlement::Internalization::Enable);
        let gas_needed_for_tx = self.simulator.gas(tx).await?;
        if gas_needed_for_tx > settlement.gas.limit {
            return Err(infra::simulator::Error::Revert(RevertError {
                err: SimulatorError::GasExceeded(gas_needed_for_tx, settlement.gas.limit),
                tx: tx.clone(),
                block: self.eth.current_block().borrow().number.into(),
            }));
        }
        Ok(())
    }

    #[instrument(skip_all)]
    async fn without_unsupported_orders(&self, mut auction: Auction) -> Auction {
        if !self.solver.config().flashloans_enabled {
            auction.orders.retain(|o| o.app_data.flashloan().is_none());
        }
        self.risk_detector
            .filter_unsupported_orders_in_auction(auction)
            .await
    }
}

const MAX_SOLUTIONS_TO_MERGE: usize = 10;

/// Creates a vector with all possible combinations of the given solutions.
/// The result is sorted descending by score.
fn merge(
    solutions: impl Iterator<Item = Solution>,
    auction: &Auction,
    max_orders_per_merged_solution: usize,
) -> Vec<Solution> {
    let mut merged: Vec<Solution> = Vec::new();
    // Limit the number of solutions to merge to avoid combinatorial explosion
    // (2^MAX_SOLUTIONS).
    for solution in solutions.take(MAX_SOLUTIONS_TO_MERGE) {
        let mut extension = vec![];
        for already_merged in merged.iter() {
            if let Ok(merged) = solution.merge(already_merged, max_orders_per_merged_solution) {
                observe::merged(&solution, already_merged, &merged);
                extension.push(merged);
            }
        }

        // At least insert the current solution
        extension.push(solution);
        merged.extend(extension);
    }

    // Sort merged solutions descending by score.
    merged.sort_by_key(|solution| {
        Reverse(
            solution
                .scoring(
                    &auction.native_prices(),
                    auction.surplus_capturing_jit_order_owners(),
                )
                .map(|score| score.0)
                .unwrap_or_default(),
        )
    });
    merged
}

struct SettleRequest {
    auction_id: auction::Id,
    solution_id: u64,
    submission_deadline: BlockNo,
    response_sender: oneshot::Sender<Result<Settled, Error>>,
    tracing_span: tracing::Span,
}

/// Solution information sent to the protocol by the driver before the solution
/// ranking happens.
#[derive(Debug)]
pub struct Solved {
    pub id: solution::Id,
    pub score: eth::Ether,
    pub trades: HashMap<order::Uid, Amounts>,
    pub prices: HashMap<eth::TokenAddress, eth::TokenAmount>,
    pub gas: Option<eth::Gas>,
}

#[derive(Debug)]
pub struct Amounts {
    pub side: order::Side,
    /// The sell token and limit sell amount of sell token.
    pub sell: eth::Asset,
    /// The buy token and limit buy amount of buy token.
    pub buy: eth::Asset,
    /// The effective amount that left the user's wallet including all fees.
    pub executed_sell: eth::TokenAmount,
    /// The effective amount the user received after all fees.
    pub executed_buy: eth::TokenAmount,
}

#[derive(Clone, Debug)]
pub struct PriceLimits {
    pub sell: eth::TokenAmount,
    pub buy: eth::TokenAmount,
}

/// Winning solution information revealed to the protocol by the driver before
/// the onchain settlement happens. Calldata is first time revealed at this
/// point.
#[derive(Debug)]
pub struct Revealed {
    /// The internalized calldata is the final calldata that appears onchain.
    pub internalized_calldata: Bytes,
    /// The uninternalized calldata must be known so that the CoW solver team
    /// can manually enforce certain rules which can not be enforced
    /// automatically.
    pub uninternalized_calldata: Bytes,
}

#[derive(Debug)]
pub struct Settled {
    /// The transaction hash in which the solution was submitted.
    pub tx_hash: eth::TxId,
    pub internalized_calldata: Bytes,
    /// The uninternalized calldata must be known so that the CoW solver team
    /// can manually enforce certain rules which can not be enforced
    /// automatically.
    pub uninternalized_calldata: Bytes,
}

#[derive(Debug, thiserror::Error)]
pub enum Error {
    #[error(
        "no solution is available yet, this might mean that /settle was called before /solve \
         returned"
    )]
    SolutionNotAvailable,
    #[error("{0:?}")]
    DeadlineExceeded(#[from] time::DeadlineExceeded),
    #[error("solver error: {0:?}")]
    Solver(#[from] solver::Error),
    #[error("failed to submit the solution")]
    SubmissionError,
    #[error("too many pending settlements for the same solver")]
    TooManyPendingSettlements,
    #[error("no valid orders found in the auction")]
    NoValidOrdersFound,
    #[error("could not parse the request")]
    MalformedRequest,
}
